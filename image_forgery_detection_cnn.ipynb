{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "image forgery cnn.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "K62zPUpU-G2O"
      },
      "source": [
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import * \n",
        "from zipfile import ZipFile\n",
        "from PIL import Image, ImageChops, ImageEnhance\n",
        "import os\n",
        "import itertools"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXift-VN-elD",
        "outputId": "115af7ad-4e30-4d8f-e2ce-e424c02ec3e7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAcTjnNS-ewA"
      },
      "source": [
        "file_name = \"/content/drive/My Drive/dataset\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITdxvYny-e_4"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "        rotation_range=40,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode='nearest')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lB7-3R02--Mg"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "        rotation_range=40,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode='nearest')\n",
        "\n",
        "img = load_img('/content/drive/My Drive/dataset/test/tu/Tp_D_CNN_M_N_cha00026_cha00028_11784.jpg')  # this is a PIL image\n",
        "x = img_to_array(img)  # this is a Numpy array with shape (3, 150, 150)\n",
        "x = x.reshape((1,) + x.shape)  # this is a Numpy array with shape (1, 3, 150, 150)\n",
        "\n",
        "# the .flow() command below generates batches of randomly transformed images\n",
        "# and saves the results to the `preview/` directory\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CNo_jzHBv0y"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), input_shape=(440,440,3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9XZJp7ECLzg"
      },
      "source": [
        "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
        "model.add(Dense(64))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NuKcgIjNCQhg",
        "outputId": "de9057fd-f9f9-4b84-b23a-50167b2bccf2"
      },
      "source": [
        "batch_size = 30\n",
        "\n",
        "# this is the augmentation configuration we will use for training\n",
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True)\n",
        "\n",
        "# this is the augmentation configuration we will use for testing:\n",
        "# only rescaling\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# this is a generator that will read pictures found in\n",
        "# subfolers of 'data/train', and indefinitely generate\n",
        "# batches of augmented image data\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        '/content/drive/My Drive/dataset/1train',  # this is the target directory\n",
        "        target_size=(440, 440),  # all images will be resized to 150x150\n",
        "        batch_size=batch_size,\n",
        "        class_mode='binary')  # since we use binary_crossentropy loss, we need binary labels\n",
        "\n",
        "# this is a similar generator, for validation data\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        '/content/drive/My Drive/dataset/test',\n",
        "        target_size=(440, 440),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='binary')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 448 images belonging to 2 classes.\n",
            "Found 448 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDjf6jqMCqk5",
        "outputId": "e39e1877-4277-49f7-d31d-b553ccf2a0e0"
      },
      "source": [
        "\n",
        "history = model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=10,\n",
        "    epochs = 50,\n",
        "    validation_data = validation_generator,\n",
        "    validation_steps=800\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5423 - accuracy: 0.7248WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 800 batches). You may need to use the repeat() function when building your dataset.\n",
            "10/10 [==============================] - 16s 2s/step - loss: 0.5423 - accuracy: 0.7248 - val_loss: 0.4916 - val_accuracy: 0.7701\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 12s 1s/step - loss: 0.5312 - accuracy: 0.7416\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 12s 1s/step - loss: 0.5227 - accuracy: 0.7148\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 12s 1s/step - loss: 0.5375 - accuracy: 0.7215\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 12s 1s/step - loss: 0.4605 - accuracy: 0.7819\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 12s 1s/step - loss: 0.5623 - accuracy: 0.7349\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 12s 1s/step - loss: 0.5917 - accuracy: 0.7450\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 12s 1s/step - loss: 0.4994 - accuracy: 0.7416\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 12s 1s/step - loss: 0.4827 - accuracy: 0.7900\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 12s 1s/step - loss: 0.4547 - accuracy: 0.7867\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 12s 1s/step - loss: 0.5534 - accuracy: 0.7517\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 12s 1s/step - loss: 0.4985 - accuracy: 0.7667\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 12s 1s/step - loss: 0.4783 - accuracy: 0.7953\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 12s 1s/step - loss: 0.4687 - accuracy: 0.7685\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 12s 1s/step - loss: 0.4340 - accuracy: 0.8020\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 12s 1s/step - loss: 0.4453 - accuracy: 0.8154\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 12s 1s/step - loss: 0.4239 - accuracy: 0.7953\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 12s 1s/step - loss: 0.4407 - accuracy: 0.7886\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 12s 1s/step - loss: 0.3895 - accuracy: 0.8121\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 12s 1s/step - loss: 0.4292 - accuracy: 0.7819\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 12s 1s/step - loss: 0.4811 - accuracy: 0.7785\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 12s 1s/step - loss: 0.4031 - accuracy: 0.8188\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 12s 1s/step - loss: 0.3781 - accuracy: 0.8289\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 12s 1s/step - loss: 0.3765 - accuracy: 0.8423\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 12s 1s/step - loss: 0.4101 - accuracy: 0.7987\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 12s 1s/step - loss: 0.3325 - accuracy: 0.8490\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 12s 1s/step - loss: 0.3813 - accuracy: 0.8200\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 12s 1s/step - loss: 0.3946 - accuracy: 0.8121\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 12s 1s/step - loss: 0.3326 - accuracy: 0.8467\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 12s 1s/step - loss: 0.3768 - accuracy: 0.8490\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 12s 1s/step - loss: 0.3160 - accuracy: 0.8624\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 12s 1s/step - loss: 0.3586 - accuracy: 0.8389\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 12s 1s/step - loss: 0.4069 - accuracy: 0.8289\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 12s 1s/step - loss: 0.3285 - accuracy: 0.8633\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 12s 1s/step - loss: 0.2870 - accuracy: 0.8624\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 12s 1s/step - loss: 0.3572 - accuracy: 0.8433\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 12s 1s/step - loss: 0.3403 - accuracy: 0.8658\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 12s 1s/step - loss: 0.3222 - accuracy: 0.8400\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 12s 1s/step - loss: 0.3556 - accuracy: 0.8100\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 12s 1s/step - loss: 0.2997 - accuracy: 0.8893\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 12s 1s/step - loss: 0.3148 - accuracy: 0.8557\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 12s 1s/step - loss: 0.3253 - accuracy: 0.8624\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 12s 1s/step - loss: 0.2407 - accuracy: 0.8758\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 12s 1s/step - loss: 0.2591 - accuracy: 0.8792\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 12s 1s/step - loss: 0.2834 - accuracy: 0.8700\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 12s 1s/step - loss: 0.3249 - accuracy: 0.8758\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 12s 1s/step - loss: 0.2481 - accuracy: 0.8833\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 12s 1s/step - loss: 0.3377 - accuracy: 0.8700\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 12s 1s/step - loss: 0.2820 - accuracy: 0.8900\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 12s 1s/step - loss: 0.2822 - accuracy: 0.9094\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v21oMv5jLfwN",
        "outputId": "a5510312-5e77-4853-dcdd-071313501fd9"
      },
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "img = image.load_img('/content/drive/My Drive/dataset/1train/au/Au_cha_00052.jpg',target_size=(440,440))\n",
        "img = image.img_to_array(img)\n",
        "img = np.expand_dims(img,axis=0)  \n",
        "ypred = model.predict(img)\n",
        "if ypred[0][0] == 1:\n",
        "  print(\"tampered image \")\n",
        "else:\n",
        "  print(\"not tampered image\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "not tampered image\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}